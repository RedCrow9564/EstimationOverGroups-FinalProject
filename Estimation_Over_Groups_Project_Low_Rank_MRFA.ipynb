{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimation_Over_Groups_Project-Low_Rank_MRFA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D1UOpVLpg9-O"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13de57bSHi61",
        "colab_type": "text"
      },
      "source": [
        "#Estimation And Approximation Problems Over Groups (Spring 2020) - Final Project\n",
        "## Low-Rank Multi-Refrence Factor Analysis Results Reconstruction- Elad Eatah\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/RedCrow9564/SpectralMethodsProject-RandomSVD/blob/master/Spectral_Methods_Project_Random_SVD.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
        "[![MIT License](https://img.shields.io/apm/l/atomic-design-ui.svg?)](https://github.com/tterb/atomic-design-ui/blob/master/LICENSEs)\n",
        "\n",
        "Complete description of this project is available in [this repo](https://github.com/RedCrow9564/EstimationOverGroups-FinalProject.git).\n",
        "\n",
        "## Getting Started\n",
        "First run the nodes under \"Infrastructure\" one by one.\n",
        "Second, run the first two nodes under \"Main Components\".\n",
        "\n",
        "### Running Unit-Tests\n",
        "You can then run the nodes under \"UnitTests\" one by one. The results of the last node are the results of these Unit-Tests.\n",
        "\n",
        "### Performing an experiment\n",
        "This is done by running the \"main\" node. Its results are then saved to a local directory in the remote machine. Make sure this directory exists on the remote machine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1UOpVLpg9-O",
        "colab_type": "text"
      },
      "source": [
        "#Infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8E4qBuoHdk5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "582b34ca-c268-4726-9863-ee0f731e2889"
      },
      "source": [
        "#@title Dependencies installations\n",
        "!pip install cvxpy cvxopt nptyping sacred pandas\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import warnings\n",
        "import psutil\n",
        "from multiprocessing import Pool\n",
        "import pandas as pd\n",
        "import os\n",
        "import pyximport\n",
        "import cython\n",
        "import cvxpy as cp\n",
        "from sacred import Experiment\n",
        "from time import perf_counter\n",
        "import cpuinfo\n",
        "import warnings\n",
        "#warnings.filterwarnings(\"error\")  # Uncomment to see warnings as errors.\n",
        "%load_ext Cython\n",
        "\n",
        "# Defining the \"sacred\" experiment object.\n",
        "ex = Experiment(name=\"Initializing project\", interactive=True)\n",
        "clear_output()\n",
        "print(\"Installation is done!\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installation is done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3HXrUa4jKiw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "079e32bc-d58d-4b99-9203-351b2b180c57"
      },
      "source": [
        "#@title Common Utils\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "utils.py - The common utilities functions and objects\n",
        "=====================================================\n",
        "\n",
        "This module contains all frequently-used methods and objects which can be shared among the entire project.\n",
        "For example, data types name used for type-hinting, a basic enum class :class:`BaseEnum`, methods for measuring\n",
        "run-time of a given function.\n",
        "\"\"\"\n",
        "from typing import List, Dict, Callable, Union, Iterator, Tuple, Any, TypeVar\n",
        "from nptyping import NDArray\n",
        "import inspect\n",
        "\n",
        "# Naming data types for type hinting.\n",
        "Scalar = Union[float, complex]\n",
        "Vector = NDArray[(Any,), Any]\n",
        "Matrix = NDArray[(Any, Any), Any]\n",
        "ThreeDMatrix = NDArray[(Any, Any, Any), Any]\n",
        "\n",
        "\n",
        "class _MetaEnum(type):\n",
        "    \"\"\"\n",
        "    A private meta-class which given any :class:`BaseEnum` object to be an iterable.\n",
        "    This can be used for iterating all possible values of this enum. Should not be used explicitly.\n",
        "    \"\"\"\n",
        "    def __iter__(self) -> Iterator:\n",
        "        \"\"\"\n",
        "        This method gives any BaseEnum the ability of iterating over all the enum's values.\n",
        "\n",
        "        Returns:\n",
        "            An iterator for the collection of all the enum's values.\n",
        "\n",
        "        \"\"\"\n",
        "        # noinspection PyUnresolvedReferences\n",
        "        return self.enum_iter()\n",
        "\n",
        "    def __contains__(self, item) -> bool:\n",
        "        \"\"\"\n",
        "        This method give any BaseEnum the ability to test if a given item is a possible value for this enum class.\n",
        "\n",
        "        Returns:\n",
        "            A flag which indicates if 'item' is a possible value for this enum class.\n",
        "\n",
        "        \"\"\"\n",
        "        # noinspection PyUnresolvedReferences\n",
        "        return self.enum_contains(item)\n",
        "\n",
        "\n",
        "class BaseEnum(metaclass=_MetaEnum):\n",
        "    \"\"\"\n",
        "    A basic interface for all enum classes. Should be sub-classed in eny enum, i.e ``class ExperimentType(BaseEnum)``\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def enum_iter(cls) -> Iterator:\n",
        "        \"\"\"\n",
        "        This method gives any BaseEnum the ability of iterating over all the enum's values.\n",
        "\n",
        "        Returns:\n",
        "            An iterator for the collection of all the enum's values.\n",
        "\n",
        "        \"\"\"\n",
        "        return iter(cls.get_all_values())\n",
        "\n",
        "    @classmethod\n",
        "    def enum_contains(cls, item) -> bool:\n",
        "        \"\"\"\n",
        "        This method give any BaseEnum the ability to test if a given item is a possible value for this enum class.\n",
        "\n",
        "        Returns:\n",
        "            A flag which indicates if 'item' is a possible value for this enum class.\n",
        "\n",
        "        \"\"\"\n",
        "        return item in cls.get_all_values()\n",
        "\n",
        "    @classmethod\n",
        "    def get_all_values(cls) -> List:\n",
        "        \"\"\"\n",
        "        A method which fetches all possible values of an enum. Used for iterating over an enum.\n",
        "\n",
        "        Returns:\n",
        "            A list of all possible enum's values.\n",
        "\n",
        "        \"\"\"\n",
        "        all_attributes: List = inspect.getmembers(cls, lambda a: not inspect.ismethod(a))\n",
        "        all_attributes = [value for name, value in all_attributes if not (name.startswith('__') or name.endswith('__'))]\n",
        "        return all_attributes\n",
        "\n",
        "\n",
        "def create_factory(possibilities_dict: Dict[str, Callable], are_methods: bool = False) -> Callable:\n",
        "    \"\"\"\n",
        "    A generic method for creating factories for the entire project.\n",
        "\n",
        "    Args:\n",
        "        possibilities_dict(Dict[str, Callable]): The dictionary which maps object types (as strings!) and returns the\n",
        "            relevant class constructors.\n",
        "        are_methods(bool): A flag, true if the factory output are methods, rather than objects. Defaults to False\n",
        "\n",
        "    Returns:\n",
        "         The factory function for the given classes/methods mapping.\n",
        "\n",
        "    \"\"\"\n",
        "    def factory_func(requested_object_type: str):  # Inner function!\n",
        "        if requested_object_type not in possibilities_dict:\n",
        "            raise ValueError(\"Object type {0} is NOT supported\".format(requested_object_type))\n",
        "        else:\n",
        "            if are_methods:\n",
        "                return possibilities_dict[requested_object_type]\n",
        "            else:\n",
        "                return possibilities_dict[requested_object_type]()\n",
        "\n",
        "    return factory_func\n",
        "\n",
        "\n",
        "def measure_time(method: Callable) -> Callable:\n",
        "    \"\"\"\n",
        "    A method which receives a method and returns the same method, while including run-time measure\n",
        "    output for the given method, in seconds.\n",
        "\n",
        "    Args:\n",
        "        method(Callable): A method whose run-time we are interested in measuring.\n",
        "\n",
        "    Returns:\n",
        "        A function which does exactly the same, with an additional run-time output value in seconds.\n",
        "\n",
        "    \"\"\"\n",
        "    def timed(*args, **kw):\n",
        "        ts = perf_counter()\n",
        "        result = method(*args, **kw)\n",
        "        te = perf_counter()\n",
        "        duration_in_ms: float = te - ts\n",
        "        if isinstance(result, tuple):\n",
        "            return result + (duration_in_ms,)\n",
        "        else:\n",
        "            return result, duration_in_ms\n",
        "    timed.__name__ = method.__name__ + \" with time measure\"\n",
        "    return timed\n",
        "\n",
        "\n",
        "def is_empty(collection: List) -> bool:\n",
        "    return len(collection) == 0\n",
        "\n",
        "\n",
        "class DataLog:\n",
        "    \"\"\"\n",
        "    A class for log-management objects. See the following example for creating it: ``DataLog([\"Column 1\", \"Column 2\"])``\n",
        "    \"\"\"\n",
        "    def __init__(self, log_fields: List):\n",
        "        \"\"\"\n",
        "        This methods initializes an empty log.\n",
        "\n",
        "        Args:\n",
        "            log_fields(List) - A list of column names for this log.\n",
        "\n",
        "        \"\"\"\n",
        "        self._data: Dict = dict()\n",
        "        self._log_fields: List = log_fields\n",
        "        for log_field in log_fields:\n",
        "            self._data[log_field] = list()\n",
        "\n",
        "    def append(self, data_type: str, value: Scalar) -> None:\n",
        "        \"\"\"\n",
        "        This methods appends given data to the given column inside the log.\n",
        "        Example of usage:``log.append(DataFields.DataSize, 20)``\n",
        "\n",
        "        Args:\n",
        "            data_type(LogFields): The column name in which the input data in inserted to.\n",
        "            value(Scalar): The value to insert to the log.\n",
        "\n",
        "        \"\"\"\n",
        "        self._data[data_type].append(value)\n",
        "\n",
        "    def append_dict(self, data_dict: Dict) -> None:\n",
        "        \"\"\"\n",
        "        This methods takes the data from the input dictionary and inserts it to this log.\n",
        "\n",
        "        Args:\n",
        "            data_dict(Dict): The dictionary from which new data is taken and inserted to the log.\n",
        "\n",
        "        \"\"\"\n",
        "        for log_field, data_value in data_dict.items():\n",
        "            self.append(log_field, data_value)\n",
        "\n",
        "    def save_log(self, log_file_name: str, results_folder_path: str) -> None:\n",
        "        \"\"\"\n",
        "        This method saves the log to a file, with the input name, in the input folder path.\n",
        "\n",
        "        Args:\n",
        "            log_file_name(str): The name for this log file.\n",
        "            results_folder_path(str): The path in which this log will be saved.\n",
        "\n",
        "        \"\"\"\n",
        "        df = pd.DataFrame(self._data, columns=self._log_fields)\n",
        "        df.to_csv(os.path.join(results_folder_path, log_file_name + \".csv\"), sep=\",\", float_format=\"%.2E\", index=False)\n",
        "        ex.info[\"Experiment Log\"] = self._data\n",
        "\n",
        "print(\"Loaded Utils Successfully!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Utils Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfvxkf_nmacU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b3691256-2f0d-451f-e15e-7c51a20cab62"
      },
      "source": [
        "#@title Enums\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "enums.py - All enums section\n",
        "============================\n",
        "\n",
        "This module contains all possible enums of this project. Most of them are used by the configuration section in\n",
        ":mod:`main`. An example for using enum:\n",
        "::\n",
        "    DistributionType.Uniform\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class LogFields(BaseEnum):\n",
        "    \"\"\"\n",
        "    The enum class of fields within experiments logs. Possible values:\n",
        "\n",
        "    * ``LogFields.DataSize``\n",
        "\n",
        "    * ``LogFields.DataType``\n",
        "\n",
        "    * ``LogFields.ApproximationRank``\n",
        "\n",
        "    * ``LogFields.ObservationsNumber``\n",
        "\n",
        "    * ``LogFields.NoisePower``\n",
        "\n",
        "    * ``LogFields.TrialsNum``\n",
        "\n",
        "    * ``LogFields.ShiftsDistribution``\n",
        "\n",
        "    * ``LogFields.MeanError``\n",
        "    \"\"\"\n",
        "    DataSize: str = \"Data size\"\n",
        "    DataType = \"Data type (complex/real)\"\n",
        "    ApproximationRank: str = \"r\"\n",
        "    ObservationsNumber: str = \"Observations Number\"\n",
        "    NoisePower: str = \"Noise power\"\n",
        "    TrialsNum: str = \"Number of Trials\"\n",
        "    ShiftsDistribution: str = \"Shifts Distribution\"\n",
        "    MeanError: str = \"Mean Error\"\n",
        "\n",
        "\n",
        "class DistributionType(BaseEnum):\n",
        "    \"\"\"\n",
        "    The enum class of experiment types. Possible values:\n",
        "\n",
        "    * ``DistributionType.Uniform``\n",
        "\n",
        "    * ``DistributionType.Dirac``\n",
        "\n",
        "    \"\"\"\n",
        "    Uniform: str = \"Uniform Distribution\"\n",
        "    Dirac: str = \"Dirac Delta Distribution\"\n",
        "\n",
        "\n",
        "class DistributionParams(BaseEnum):\n",
        "    \"\"\"\n",
        "    The enum class of parameters for the shifts distribution. Possible values:\n",
        "\n",
        "    * ``DistributionParams.DeltaLocations``\n",
        "\n",
        "    \"\"\"\n",
        "    DeltaLocations: str = \"delta_locations\"\n",
        "\n",
        "\n",
        "print(\"Loaded Enums Successfully!\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Enums Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAtG0iQRmqY-",
        "colab_type": "text"
      },
      "source": [
        "#Main Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PRx_3HOa5kU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad3e66f8-2514-4345-932e-f81a34650c21"
      },
      "source": [
        "#@title Data Generation\n",
        "from numpy.linalg import norm, qr\n",
        "\n",
        "\n",
        "def create_discrete_distribution(distribution_type: str, distribution_length: int, distribution_params: Dict) -> Vector:\n",
        "    if distribution_type == DistributionType.Uniform:\n",
        "        return np.ones(distribution_length) / distribution_length\n",
        "    elif distribution_type == DistributionType.Dirac:\n",
        "        delta_locations: Vector = np.array(distribution_params[DistributionParams.DeltaLocations])\n",
        "        distribution: Vector = np.zeros(distribution_length, dtype=np.float64)\n",
        "        distribution[delta_locations] = 1\n",
        "        distribution /= len(delta_locations)\n",
        "        return distribution\n",
        "\n",
        "\n",
        "def generate_covariance(signal_length: int, approximation_rank: int, data_type, random_generator) -> \\\n",
        "        (Matrix, Matrix, Vector):\n",
        "    # Picking random eigenvalues (variances) for the exact covariance matrix.\n",
        "    eigenvalues: Vector = random_generator.uniform(size=approximation_rank)\n",
        "    eigenvalues /= norm(eigenvalues, ord=1)\n",
        "    # Creating the set of orthonormal eigenvectors\n",
        "    eigenvectors: Matrix = random_generator.uniform(size=(signal_length, approximation_rank))\n",
        "    if data_type in [np.complex128, np.complex64, np.complex]:\n",
        "        eigenvectors = eigenvectors.astype(data_type)\n",
        "        eigenvectors += 1j * random_generator.uniform(size=(signal_length, approximation_rank))\n",
        "    eigenvectors = qr(eigenvectors)[0]\n",
        "    covariance: Matrix = (eigenvectors * eigenvalues).dot(np.conj(eigenvectors.T))\n",
        "    return covariance, eigenvectors, eigenvalues\n",
        "\n",
        "\n",
        "def generate_observations(eigenvectors: Matrix, eigenvalues: Vector, approximation_rank: int, observation_num: int,\n",
        "                          data_type, random_generator) -> Matrix:\n",
        "\n",
        "    # Sampling the signal from this covariance matrix.\n",
        "    standard_deviations: Matrix = np.tile(np.sqrt(eigenvalues).reshape((-1, 1)), (1, observation_num))\n",
        "    observations: Matrix = random_generator.normal(scale=standard_deviations, size=(approximation_rank, observation_num))\n",
        "    if data_type in [np.complex128, np.complex64, np.complex]:\n",
        "        standard_deviations /= np.sqrt(2)\n",
        "        observations = np.sqrt(0.5) * observations.astype(data_type)\n",
        "        observations += 1j * random_generator.normal(scale=standard_deviations, size=observations.shape)\n",
        "    observations = np.dot(eigenvectors, observations).T\n",
        "    return observations\n",
        "\n",
        "\n",
        "def generate_shifts_and_noise(observations: Matrix, shifts: List[int], noise_power: float,\n",
        "                              data_type, random_generator) -> Matrix:\n",
        "    for i, shift in enumerate(shifts):\n",
        "        observations[i] = np.roll(observations[i], shift)\n",
        "    if data_type in [np.complex128, np.complex64, np.complex]:\n",
        "        half_power_std: Scalar = np.sqrt(noise_power / 2)\n",
        "        observations += random_generator.normal(loc=0, scale=half_power_std, size=observations.shape)\n",
        "        observations += 1j * random_generator.normal(loc=0, scale=half_power_std, size=observations.shape)\n",
        "    else:\n",
        "        observations += random_generator.normal(loc=0, scale=np.sqrt(noise_power), size=observations.shape)\n",
        "    return observations\n",
        "\n",
        "\n",
        "print(\"Loaded Successfully!\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RZFeh0dbPL6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d181b5da-7149-4b46-b6b6-3932f60216bb"
      },
      "source": [
        "#@title Power-Spectrum and Tri-Spectrum Estimation\n",
        "%%cython -f\n",
        "# cython: language_level=3, boundscheck=False, wraparound=False\n",
        "# cython: initializedcheck=False, cdivision=True, nonecheck=False\n",
        "# distutils: language = c++\n",
        "\"\"\"\n",
        "polyspectra_estimation.pyx - spectrum estimations algorithms module\n",
        "===================================================================\n",
        "This module contains methods for estimating a signal's power spectrum and tri-spectrum\n",
        "from a given matrix of its observations.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "\n",
        "\n",
        "cdef extern from \"<complex>\" namespace \"std\" nogil:\n",
        "    double complex conj(double complex z)\n",
        "\n",
        "\n",
        "def estimate_power_spectrum(const complex[:, ::1] observations_fourier):\n",
        "    \"\"\"\n",
        "    The function for estimating a signal's power-spectrum from its observations.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "\n",
        "    Returns:\n",
        "        A vector :math:`P_{y}` which estimates the power-spectrum of the original signal.\n",
        "    \"\"\"\n",
        "    return np.mean(np.power(np.abs(observations_fourier), 2), axis=0)\n",
        "\n",
        "\n",
        "def estimate_tri_spectrum_naive(const complex[:, ::1] observations_fourier):\n",
        "    \"\"\"\n",
        "    The function for estimating a signal's tri-spectrum from its observations.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "\n",
        "    Returns:\n",
        "        A 3D array :math:`T_{y}` which estimates the tri-spectrum of the original signal.\n",
        "    \"\"\"\n",
        "    cdef Py_ssize_t signal_length = observations_fourier.shape[1]\n",
        "    cdef Py_ssize_t observations_num = observations_fourier.shape[0]\n",
        "    cdef np.ndarray[np.complex128_t, ndim=3] tri_spectrum = np.empty(\n",
        "        (signal_length, signal_length, signal_length), dtype=np.complex128, order='F')\n",
        "    tri_spectrum_estimation_v1(observations_fourier, signal_length, observations_num, tri_spectrum)\n",
        "    return tri_spectrum\n",
        "\n",
        "\n",
        "cdef inline void tri_spectrum_estimation_v1(const complex[:, ::1] observations_fourier,\n",
        "                                            const Py_ssize_t signal_length, const Py_ssize_t observations_num,\n",
        "                                            complex[::1, :, :] tri_spectrum):\n",
        "    \"\"\"\n",
        "    A naive calculation of the tri-spectrum as a c-level function.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "        signal_length(const Py_ssize_t): The second dimension (columns) length of the coefficients matrix.\n",
        "        observations_num(const Py_ssize_t): The first dimension (rows) length of the coefficients matrix.\n",
        "        tri_spectrum(ThreeDMatrix): An empty 3D array  of size signal_length^3 for storing the calculation's result.\n",
        "    \"\"\"\n",
        "    cdef const double complex[:] observation\n",
        "    cdef double complex temp = 0\n",
        "    cdef Py_ssize_t i, j, k, m, s\n",
        "\n",
        "    for i in range(signal_length):\n",
        "        for j in range(signal_length):\n",
        "            s = <Py_ssize_t>((i - j) % signal_length)\n",
        "            if j > i: # This line verifies the modulo operator behaves the same as modulo in Python\n",
        "                s += signal_length\n",
        "            for k in range(signal_length):\n",
        "                for m in range(observations_num):\n",
        "                    observation = observations_fourier[m]\n",
        "                    temp += observation[i] * conj(observation[j]) * observation[k] * conj(observation[s])\n",
        "                tri_spectrum[i, j, k] = temp / <double complex>observations_num\n",
        "                s = (s + 1) % signal_length\n",
        "                temp = 0\n",
        "\n",
        "\n",
        "def estimate_tri_spectrum_v2(const complex[:, ::1] observations_fourier):\n",
        "    \"\"\"\n",
        "    The function for estimating a signal's tri-spectrum from its observations.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "\n",
        "    Returns:\n",
        "        A 3D array :math:`T_{y}` which estimates the tri-spectrum of the original signal.\n",
        "    \"\"\"\n",
        "    cdef Py_ssize_t signal_length = observations_fourier.shape[1]\n",
        "    cdef Py_ssize_t observations_num = observations_fourier.shape[0]\n",
        "    cdef np.ndarray[np.complex128_t, ndim=3] trispectrum = np.empty(\n",
        "        (signal_length, signal_length, signal_length), dtype=np.complex128, order='F')\n",
        "    tri_spectrum_estimation_v2(observations_fourier, signal_length, observations_num, trispectrum)\n",
        "    return trispectrum\n",
        "\n",
        "\n",
        "cdef inline void tri_spectrum_estimation_v2(const complex[:, ::1] observations_fourier,\n",
        "                                            const Py_ssize_t signal_length, const Py_ssize_t observations_num,\n",
        "                                            complex[::1, :, :] tri_spectrum):\n",
        "    \"\"\"\n",
        "    An improved calculation of the tri-spectrum as a c-level function, which applies a type of symmetry.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "        signal_length(const Py_ssize_t): The second dimension (columns) length of the coefficients matrix.\n",
        "        observations_num(const Py_ssize_t): The first dimension (rows) length of the coefficients matrix.\n",
        "        tri_spectrum(ThreeDMatrix): An empty 3D array  of size signal_length^3 for storing the calculation's result.\n",
        "    \"\"\"\n",
        "    #TODO: Improve efficiency of this method by applying MORE symmetries\n",
        "    cdef const double complex[:] observation\n",
        "    cdef double complex temp = 0\n",
        "    cdef Py_ssize_t i, j, k, m, s\n",
        "\n",
        "    for i in range(signal_length):\n",
        "        for j in range(signal_length):\n",
        "            for k in range(i):  # Applying a symmetry of the tri-spectrum: T[x,y,z]=T[z,y,x]\n",
        "                tri_spectrum[i, j, k] = tri_spectrum[k, j, i]\n",
        "\n",
        "            s = <Py_ssize_t>(2 * i - j) % signal_length\n",
        "            if j > 2 * i:  # This line verifies the modulo operator behaves the same as modulo in Python\n",
        "                s += signal_length\n",
        "            for k in range(i, signal_length):\n",
        "                for m in range(observations_num):\n",
        "                    observation = observations_fourier[m]\n",
        "                    temp += observation[i] * conj(observation[j]) * observation[k] * conj(observation[s])\n",
        "                tri_spectrum[i, j, k] = temp / <double complex>observations_num\n",
        "                s = (s + 1) % signal_length\n",
        "                temp = 0\n",
        "\n",
        "print(\"Loaded Successfully!\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUaZlxljPBV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8509fded-28a9-4bdf-e0f8-3cb43a508e68"
      },
      "source": [
        "#@title Vectorized Actions\n",
        "%%cython -f\n",
        "# cython: language_level=3, boundscheck=False, wraparound=False\n",
        "# cython: initializedcheck=False, cdivision=True, nonecheck=False\n",
        "# distutils: language = c++\n",
        "\"\"\"\n",
        "vectorized_actions.pyx - vectorized algorithms module\n",
        "======================================================\n",
        "This module contains methods for are implemented in Cython for run-time improvements\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "from numpy import kron\n",
        "from scipy.linalg import eigh\n",
        "from libc.math cimport sqrt\n",
        "\n",
        "# A type which represents either a double-precision real number (64 bit - np.float64) or a double-precision\n",
        "# complex number (128 bit - np.complex128).\n",
        "ctypedef fused double_or_complex:\n",
        "    complex\n",
        "    double\n",
        "\n",
        "def extract_diagonals(double_or_complex[::1, :, :] matrices_arr, const int signal_length):\n",
        "    \"\"\"\n",
        "    The function calculates the eigenvector of each matrices_arr[i] which corresponds to the largest (in magnitude)\n",
        "    eigenvalue. This eigenvector is scaled by the square-root of the matching eigenvalue and stored as the i-th row\n",
        "    of the result matrix.\n",
        "\n",
        "    Args:\n",
        "        matrices_arr(ThreeDMatrix): The matrices list, where square matrices are stored along the first dimension of\n",
        "            the array, i.e matrices_arr[i] is the i-th square matrix in the array.\n",
        "        signal_length(const int): The length of each dimension of all square matrices.\n",
        "\n",
        "    Returns:\n",
        "        A square matrix such that its i-th row is the scaled leading eigenvector of matrices_arr[i].\n",
        "    \"\"\"\n",
        "    cdef Py_ssize_t i, j\n",
        "    cdef double[:] eigenvalue\n",
        "    cdef double first_scaled_eigenvalue\n",
        "    cdef double_or_complex[:, :] eigenvector\n",
        "    cdef np.ndarray[double_or_complex, ndim=2] diagonals = np.empty((signal_length - 1, signal_length),\n",
        "                                                                    dtype=matrices_arr.base.dtype, order=\"F\")\n",
        "\n",
        "    for i in range(signal_length - 1):\n",
        "        eigenvalue, eigenvector = eigh(\n",
        "            matrices_arr[i], overwrite_a = True, overwrite_b = True, check_finite = False,\n",
        "            eigvals=(signal_length - 1, signal_length - 1))\n",
        "        first_scaled_eigenvalue = sqrt(eigenvalue[0])\n",
        "        for j in range(signal_length):\n",
        "            diagonals[i, j] = first_scaled_eigenvalue * eigenvector[j, 0]\n",
        "\n",
        "    return diagonals\n",
        "\n",
        "\n",
        "def vectorized_kron(double_or_complex[::1, :, :] matrices_arr):\n",
        "    \"\"\"\n",
        "    The function for performing Kronecker product between each two consecutive matrices in a large 3D matrix\n",
        "\n",
        "    Args:\n",
        "        matrices_arr(ThreeDMatrix): The matrices list, where matrices are stored along the first dimension of\n",
        "            the array, i.e matrices_arr[i] is the i-th matrix in the array.\n",
        "\n",
        "    Returns:\n",
        "        A 3D array which stores all these Kronecker products along its first axis.\n",
        "    \"\"\"\n",
        "    cdef Py_ssize_t rows = matrices_arr.shape[1]\n",
        "    cdef Py_ssize_t cols = matrices_arr.shape[2]\n",
        "    cdef Py_ssize_t rows_sqr = rows * rows\n",
        "    cdef Py_ssize_t cols_sqr = cols * cols\n",
        "    cdef np.ndarray[double_or_complex, ndim=3] results = np.empty((rows, rows_sqr, cols_sqr),\n",
        "                                                                  dtype=matrices_arr.base.dtype, order=\"F\")\n",
        "    cdef Py_ssize_t i = 0\n",
        "\n",
        "    if double_or_complex is complex:\n",
        "        for i in range(rows - 1):\n",
        "            results[i] = kron(np.conj(matrices_arr[i + 1]), matrices_arr[i])\n",
        "        results[rows - 1] = kron(np.conj(matrices_arr[0]), matrices_arr[rows - 1])\n",
        "    else:\n",
        "        for i in range(rows - 1):\n",
        "            results[i] = kron(matrices_arr[i + 1], matrices_arr[i])\n",
        "        results[rows - 1] = kron(matrices_arr[0], matrices_arr[rows - 1])\n",
        "    return results\n",
        "\n",
        "\n",
        "def construct_estimator(double_or_complex[::1, :] diagonals, const double[::1] power_spectrum,\n",
        "                        const int signal_length, const float noise_power):\n",
        "    \"\"\"\n",
        "    The function creates a signal_length times signal_length matrix such that the i-th row of the diagonals matrix\n",
        "    is the i-th diagonal of the matrix (with wrapping) for all 1<i<signal_length. The mai diagonal of this matrix\n",
        "    is set to the power-spectrum estimation, minus the estimated noise power.\n",
        "\n",
        "    Args:\n",
        "        diagonals(Matrix): A 2D square matrix of size signal_length times signal_length.\n",
        "        power_spectrum(const double[::1]): A vector of size signal_length which estimates of the signal's\n",
        "            power-spectrum.\n",
        "        signal_length(const int): The length of each dimension of all square matrices.\n",
        "        noise_power(const float): An estimation for the signal's noise power :math:`\\sigma^{2}`.\n",
        "\n",
        "    Returns:\n",
        "        A 3D array which stores all these Kronecker products along its first axis.\n",
        "    \"\"\"\n",
        "    cdef np.ndarray[double_or_complex, ndim=2] estimator = np.empty((signal_length, signal_length),\n",
        "                                                                    dtype=diagonals.base.dtype)\n",
        "    cdef Py_ssize_t i, j, column_index\n",
        "\n",
        "    # Constructing the main diagonal of the estimator.\n",
        "    for i in range(signal_length):\n",
        "        estimator[i, i] = <double_or_complex>(power_spectrum[i] - noise_power)\n",
        "\n",
        "    # Constructing the off-diagonal terms.\n",
        "    for i in range(1, signal_length):\n",
        "        for j in range(signal_length):\n",
        "            column_index = <Py_ssize_t>((i + j) % signal_length)\n",
        "            estimator[j, column_index] = diagonals[i - 1, j]\n",
        "\n",
        "    return estimator\n",
        "\n",
        "print(\"Loaded Successfully!\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s-athYbWW9H",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f2bd1b-636b-430f-d439-33f7ead289eb"
      },
      "source": [
        "#@title Covariance Estimation\n",
        "from numpy.fft import ifft, fft\n",
        "from scipy.linalg import eigh, block_diag, circulant\n",
        "\n",
        "\n",
        "def low_rank_multi_reference_factor_analysis(\n",
        "        observations_fourier: Matrix, signal_length: int, approximation_rank: Union[int, None],\n",
        "        noise_power: float, data_type, exact_covariance) -> Matrix:\n",
        "    \"\"\"\n",
        "    The entire algorithm fot the covariance estimation. It consists of two stages, see Algorithm 1 and Algorithm 2 in\n",
        "    the paper.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "        signal_length(int): The length of the signal.\n",
        "        approximation_rank(int): The rank of the approximated covariance matrix.\n",
        "        noise_power(float): An estimator for the noise power in the sampled observations.\n",
        "        data_type: Either np.float64 for real-data or np.complex128 for complex data.\n",
        "        exact_covariance(Matrix): The covariance which this algorithm estimated. It is used ONLY for\n",
        "            testing, debugging and verifying the technical conditions which are required for this algorithm.\n",
        "\n",
        "    Returns:\n",
        "        The estimated covariance matrix.\n",
        "\n",
        "    \"\"\"\n",
        "    # TODO: Remove the exact_covariance argument for real experiments.\n",
        "    estimator: Matrix = estimate_covariance_up_to_phases(observations_fourier, signal_length, noise_power, data_type,\n",
        "                                                         exact_covariance)\n",
        "    estimator = phase_retrieval(estimator, signal_length, approximation_rank)\n",
        "    return estimator\n",
        "\n",
        "\n",
        "def estimate_covariance_up_to_phases(observations_fourier: Matrix, signal_length: int, noise_power: float,\n",
        "                                     data_type, exact_covariance) -> Matrix:\n",
        "    \"\"\"\n",
        "    The first stage algorithm fot the covariance estimation, see Algorithm 1 in the paper.\n",
        "\n",
        "    Args:\n",
        "        observations_fourier(Matrix): The fourier coefficients of all observations.\n",
        "        signal_length(int): The length of the signal.\n",
        "        noise_power(float): An estimator for the noise power in the sampled observations.\n",
        "        data_type: Either np.float64 for real-data or np.complex128 for complex data.\n",
        "        exact_covariance(Matrix): The covariance which this algorithm estimated. It is used ONLY for\n",
        "            testing, debugging and verifying the technical conditions which are required for this algorithm.\n",
        "\n",
        "    Returns:\n",
        "        The estimated covariance matrix, up to multiplication by a circulant matrix of complex phases.\n",
        "\n",
        "    \"\"\"\n",
        "    power_spectrum: Vector = estimate_power_spectrum(observations_fourier)\n",
        "    tri_spectrum: ThreeDMatrix = estimate_tri_spectrum_v2(observations_fourier)\n",
        "\n",
        "    # TODO: Remove the exact_covariance argument\n",
        "    exact_cov_fourier_basis: Matrix = np.conj(fft(exact_covariance, axis=0, norm=\"ortho\").T)\n",
        "    exact_cov_fourier_basis: Matrix = np.conj(fft(exact_cov_fourier_basis, axis=0, norm=\"ortho\").T)\n",
        "    if np.any(np.abs(exact_covariance)) < 1e-15:\n",
        "        warnings.warn(\"The covariance matrix in Fourier basis has some 0 entries, consistency is NOT guaranteed!\",\n",
        "                      Warning)\n",
        "    print(f'Covariance Fourier Diagonal: {np.real(np.diag(exact_cov_fourier_basis))}')\n",
        "    print(f'Power spectrum: {power_spectrum}')\n",
        "    # exact_tri_spectrum: ThreeDMatrix = calc_exact_tri_spectrum(exact_cov_fourier_basis, data_type)\n",
        "    # print(f'Max tri-spectrum estimation error: {np.max(np.abs(exact_tri_spectrum - tri_spectrum))}')\n",
        "\n",
        "    # Optimization step\n",
        "    g = perform_optimization(tri_spectrum, power_spectrum, signal_length, data_type)\n",
        "    diagonals: Matrix = extract_diagonals(g, signal_length)\n",
        "    estimated_covariance: Matrix = construct_estimator(diagonals, power_spectrum, signal_length, noise_power)\n",
        "    return estimated_covariance\n",
        "\n",
        "\n",
        "def create_optimization_objective(tri_spectrum, power_spectrum, data_type) -> Callable:\n",
        "    g_zero = np.outer(power_spectrum, power_spectrum)\n",
        "    signal_length = len(power_spectrum)\n",
        "\n",
        "    def objective(matrices_list):\n",
        "        fit_score = 0.0\n",
        "        for k1 in range(signal_length):\n",
        "            for k2 in range(signal_length):\n",
        "                other_index = (k2 - k1) % signal_length\n",
        "                for m in range(signal_length):\n",
        "                    k1_plus_m = (k1 + m) % signal_length\n",
        "                    current_term = tri_spectrum[k1, k1_plus_m, (k2 + m) % signal_length]\n",
        "                    if other_index == 0:\n",
        "                        current_term -= g_zero[k1, k1_plus_m]\n",
        "                    else:\n",
        "                        current_term -= matrices_list[other_index - 1][k1, k1_plus_m]\n",
        "\n",
        "                    if m == 0:\n",
        "                        current_term -= g_zero[k1, k2]\n",
        "                    else:\n",
        "                        current_term -= matrices_list[m - 1][k1, k2]\n",
        "\n",
        "                    if data_type in [np.float32, np.float64]:\n",
        "                        next_index: int = (k1 + k2 + m) % signal_length\n",
        "                        if next_index == 0:\n",
        "                            current_term -= g_zero[- k2 % signal_length, (-k2 - m) % signal_length]\n",
        "                        else:\n",
        "                            current_term -= matrices_list[next_index - 1][\n",
        "                                - k2 % signal_length, (-k2 - m) % signal_length]\n",
        "\n",
        "                    fit_score += cp.abs(current_term) ** 2\n",
        "        return fit_score\n",
        "    return objective\n",
        "\n",
        "\n",
        "def perform_optimization(tri_spectrum: ThreeDMatrix, power_spectrum: Matrix, signal_length: int,\n",
        "                         data_type) -> ThreeDMatrix:\n",
        "    optimization_objective: Callable = create_optimization_objective(tri_spectrum, power_spectrum, data_type)\n",
        "    symbolic_matrices = [cp.Variable((signal_length, signal_length), PSD=True, name=f'G{i + 1}')\n",
        "                         for i in range(signal_length - 1)]\n",
        "    problem = cp.Problem(cp.Minimize(optimization_objective(symbolic_matrices)), [])\n",
        "\n",
        "    min_fit_score = problem.solve(solver=cp.SCS)\n",
        "    optimization_result = [mat.value for mat in symbolic_matrices]\n",
        "\n",
        "    print(f'Min score: {min_fit_score}')\n",
        "    print(f'Are matrices None? {[(mat is None) for mat in optimization_result]}')\n",
        "    print(f'Are matrices Hermitian? {[np.allclose(np.conj(mat), mat) for mat in optimization_result]}')\n",
        "    print(f'Are matrices PSD? {[np.all(np.linalg.eigvalsh(mat) >= 0) for mat in optimization_result]}')\n",
        "\n",
        "    return np.array(optimization_result, order='F')\n",
        "\n",
        "\n",
        "def phase_retrieval(covariance_estimator: Matrix, signal_length: int, approximation_rank: Union[int, None]) -> Matrix:\n",
        "    \"\"\"\n",
        "    The first stage algorithm fot the covariance estimation, see Algorithm 2 in the paper. This stage solves the\n",
        "    phase ambiguity (up to the inherent ambiguity of the problem).\n",
        "\n",
        "    Args:\n",
        "        covariance_estimator(Matrix): The estimator which is given as the output of the first stage of the algorithm\n",
        "            (Algorithm 1 in the paper).\n",
        "        signal_length(int): The length of the signal.\n",
        "        approximation_rank(int): The rank of the approximated covariance matrix.\n",
        "\n",
        "    Returns:\n",
        "        The estimated covariance matrix, up to the inherent ambiguity of the problem\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Building the coefficients matrix A.\n",
        "    matrix_a: Matrix = coefficient_matrix_construction(covariance_estimator, signal_length, approximation_rank)\n",
        "    # Finding the singular vector which corresponds to the smallest singular-value of A.\n",
        "    b = np.dot(np.conj(matrix_a).T, matrix_a)\n",
        "    val, v = eigh(b, overwrite_a=False, overwrite_b=False, check_finite=False, eigvals=(0, 2))\n",
        "    if abs(val[1]) < 1e-15:\n",
        "        warnings.warn(\"The dimension of the null-space of A is larger the one, so this estimator \" +\n",
        "                      \"is NOT guaranteed to succeed!\", Warning)\n",
        "\n",
        "    # Finding the matching angles\n",
        "    angles = estimate_angles(v, signal_length)\n",
        "    phases: Vector = np.exp(-1j * angles)\n",
        "    phases = np.insert(phases, 0, 1)\n",
        "\n",
        "    # Multiplying by the negative phases to find the Fourier-basis covariance\n",
        "    covariance_estimator = np.multiply(covariance_estimator, circulant(phases))\n",
        "\n",
        "    # Converting the estimator back to the standard basis\n",
        "    covariance_estimator = np.conj(ifft(covariance_estimator, axis=0, norm=\"ortho\").T)\n",
        "    covariance_estimator = np.conj(ifft(covariance_estimator, axis=0, norm=\"ortho\").T)\n",
        "    return covariance_estimator\n",
        "\n",
        "\n",
        "def coefficient_matrix_construction(covariance_estimator: Matrix, signal_length: int,\n",
        "                                    approximation_rank: Union[int, None]) -> Matrix:\n",
        "    \"\"\"\n",
        "    This function constructs a linear equations system, for solving the phase ambiguity\n",
        "    (up to the inherent ambiguity of the problem).\n",
        "\n",
        "    Args:\n",
        "        covariance_estimator(Matrix): The estimator which is given as the output of the first stage of the algorithm\n",
        "            (Algorithm 1 in the paper).\n",
        "        signal_length(int): The length of the signal.\n",
        "        approximation_rank(int): The rank of the approximated covariance matrix.\n",
        "\n",
        "    Returns:\n",
        "        A signal_length ** 3 X (1 + approximation_rank ** 4) matrix (if approximation_rank < sqrt(signal_length))\n",
        "\n",
        "    \"\"\"\n",
        "    rank_sqr: int = approximation_rank ** 2 if approximation_rank is not None else signal_length - 1\n",
        "    least_eigenvalue_index: int = max(signal_length - rank_sqr, 0)\n",
        "    last_index: int = signal_length ** 2\n",
        "    transition_index: int = last_index - signal_length\n",
        "\n",
        "    hi_i: Matrix = np.power(np.abs(covariance_estimator), 2)\n",
        "    rotated_mat: Matrix = covariance_estimator\n",
        "    all_eigenvectors: Matrix = np.empty((signal_length, signal_length, signal_length - least_eigenvalue_index),\n",
        "                                        order=\"F\", dtype=covariance_estimator.dtype)\n",
        "    all_m_mats: Matrix = np.zeros((signal_length ** 3, signal_length), dtype=covariance_estimator.dtype)\n",
        "    sampled_indices: Matrix = np.empty((signal_length, signal_length), dtype=int)\n",
        "    sampled_indices[0] = np.arange(0, last_index, signal_length + 1)\n",
        "    for m in range(1, signal_length):\n",
        "        sampled_hi_indices = np.arange(m, transition_index, signal_length + 1)\n",
        "        sampled_indices[m] = np.hstack((sampled_hi_indices, np.arange(transition_index,\n",
        "                                                                      last_index, signal_length + 1)))\n",
        "        transition_index -= signal_length\n",
        "\n",
        "    for i in range(signal_length):\n",
        "        all_eigenvectors[i] = eigh(hi_i, overwrite_b=False, check_finite=False,\n",
        "                                   eigvals=(least_eigenvalue_index, signal_length - 1))[1]\n",
        "        rotated_mat = np.roll(rotated_mat, shift=1, axis=1)\n",
        "        hi_i = np.multiply(covariance_estimator, np.conj(rotated_mat))\n",
        "        hi_i_plus_one_flat = hi_i.flatten('F')\n",
        "\n",
        "        for m in range(signal_length):\n",
        "            all_m_mats[sampled_indices[m] + i * last_index, m] = hi_i_plus_one_flat[sampled_indices[m]]\n",
        "\n",
        "        rotated_mat = np.roll(rotated_mat, shift=1, axis=0)\n",
        "        hi_i = np.multiply(covariance_estimator, np.conj(rotated_mat))\n",
        "\n",
        "    matrix_a = np.hstack((all_m_mats, -block_diag(*vectorized_kron(all_eigenvectors))))\n",
        "    return matrix_a\n",
        "\n",
        "\n",
        "def estimate_angles(eigenvector: Vector, signal_length: int) -> Vector:\n",
        "    \"\"\"\n",
        "    This function constructs a linear equations system, for solving the phase ambiguity\n",
        "    (up to the inherent ambiguity of the problem).\n",
        "\n",
        "    Args:\n",
        "        eigenvector(Vector): The eigenvector of the equations matrix which corresponds to the singular value of 0.\n",
        "        signal_length(int): The length of the signal.\n",
        "\n",
        "    Returns:\n",
        "        A vector of estimated phases.\n",
        "\n",
        "    \"\"\"\n",
        "    v = eigenvector[:, 0][:signal_length]\n",
        "    arguments_vector = np.angle(v)\n",
        "    angles = np.cumsum(arguments_vector[1:])\n",
        "    angles = -angles + (angles[signal_length - 2] + arguments_vector[0]) / signal_length * \\\n",
        "        np.arange(1, signal_length, 1)\n",
        "    return angles\n",
        "\n",
        "\n",
        "def calc_exact_tri_spectrum(exact_covariance: Matrix) -> ThreeDMatrix:\n",
        "    signal_length: int = exact_covariance.shape[0]\n",
        "    tri_spectrum = np.empty((signal_length, signal_length, signal_length), dtype=exact_covariance.dtype)\n",
        "\n",
        "    from itertools import product\n",
        "\n",
        "    for i, j, k in product(range(signal_length), range(signal_length), range(signal_length)):\n",
        "        fourth_index = (k - j + i ) % signal_length\n",
        "        tri_spectrum[i, j, k] = exact_covariance[i, j] * np.conj(exact_covariance[fourth_index, k])\n",
        "        tri_spectrum[i, j, k] += exact_covariance[i, fourth_index] * np.conj(exact_covariance[j, k])\n",
        "\n",
        "    return tri_spectrum\n",
        "\n",
        "print(\"Loaded Successfully!\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tznptTDQjPCN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "10b4f55d-feaf-4826-9984-444da17d6e54"
      },
      "source": [
        "#@title Main\n",
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "main.py - The main module of the project\n",
        "========================================\n",
        "\n",
        "This module contains the config for the experiment in the \"config\" function.\n",
        "Running this module invokes the :func:`main` function, which then performs the experiment and saves its results\n",
        "to the configured results folder. Example for running an experiment: ``python main.py``\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from numpy import roll\n",
        "from numpy.linalg import norm\n",
        "from numpy.random import Generator, PCG64\n",
        "from numpy.fft import fft\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "def calc_estimation_error(exact_covariance, estimated_covariance):\n",
        "    covariance_norm: Scalar = norm(exact_covariance, ord='fro') ** 2\n",
        "    rotated_cov: Matrix = exact_covariance\n",
        "    error: Scalar = norm(estimated_covariance - rotated_cov, ord='fro') ** 2\n",
        "\n",
        "    for _ in range(exact_covariance.shape[0]):\n",
        "        rotated_cov = roll(rotated_cov, shift=[1, 1], axis=[0, 1])\n",
        "        shifted_error = norm(estimated_covariance - rotated_cov, ord='fro') ** 2\n",
        "        if shifted_error < error:\n",
        "            error = shifted_error\n",
        "\n",
        "    return error / covariance_norm\n",
        "\n",
        "\n",
        "@ex.config\n",
        "def config():\n",
        "    \"\"\" Config section\n",
        "\n",
        "    This function contains all possible configuration for all experiments. Full details on each configuration values\n",
        "    can be found in :mod:`enums.py`.\n",
        "    \"\"\"\n",
        "\n",
        "    data_type = np.complex128\n",
        "    signal_lengths: [int] = [10]\n",
        "    observations_numbers: List[int] = [1000000]\n",
        "    approximation_ranks: List[Union[int, None]] = [2]\n",
        "    noise_powers: List[float] = [0.0]\n",
        "    trials_num: int = 1\n",
        "    first_seed: int = 200\n",
        "    shifts_distribution_type = DistributionType.Uniform\n",
        "    distribution_params: Dict = {\n",
        "        DistributionParams.DeltaLocations: [1]\n",
        "    }\n",
        "    experiment_name: str = \"Testing Code Infrastructure\"\n",
        "    results_path: str = r'Results/'\n",
        "\n",
        "\n",
        "@ex.main\n",
        "def main(signal_lengths: List[int], observations_numbers: List[int], approximation_ranks: List[int],\n",
        "         noise_powers: List[float], shifts_distribution_type: str, trials_num: int, data_type, results_path: str,\n",
        "         experiment_name: str, first_seed: int, distribution_params: Dict) -> None:\n",
        "    \"\"\" The main function of this project\n",
        "\n",
        "    This functions performs the desired experiment according to the given configuration.\n",
        "    The function runs the random_svd and random_id for every combination of data_size, approximation rank and increment\n",
        "    given in the config and saves all the results to a csv file in the results folder (given in the configuration).\n",
        "    \"\"\"\n",
        "    results_log = DataLog(LogFields)  # Initializing an empty results log.\n",
        "\n",
        "    for signal_length, noise_power, approximation_rank, observations_num in product(\n",
        "            signal_lengths, noise_powers, approximation_ranks, observations_numbers):\n",
        "        if approximation_rank >= np.sqrt(signal_length):\n",
        "            warnings.warn(f'Approximation rank {approximation_rank} is at least the square-root of the ' +\n",
        "                          f'signal length {signal_length}, consistency is NOT guaranteed!', Warning)\n",
        "        shifts_distribution: Vector = create_discrete_distribution(shifts_distribution_type, signal_length,\n",
        "                                                                   distribution_params)\n",
        "\n",
        "        mean_error: float = 0\n",
        "        trials_seeds: Vector = np.arange(first_seed, first_seed + trials_num).tolist()\n",
        "        \n",
        "        for trial_seed in trials_seeds:\n",
        "            rng = Generator(PCG64(trial_seed))  # Set trial's random generator.\n",
        "            exact_covariance, eigenvectors, eigenvalues = generate_covariance(\n",
        "                signal_length, approximation_rank, data_type, rng)\n",
        "            observations = generate_observations(eigenvectors, eigenvalues, \n",
        "                                                 approximation_rank, observations_num,\n",
        "                                                 data_type, rng)\n",
        "            observations_shifts: List[int] = rng.choice(signal_length, size=observations_num, p=shifts_distribution)\n",
        "            observations = generate_shifts_and_noise(observations, observations_shifts, noise_power, data_type, rng)\n",
        "            observations_fourier: Matrix = fft(observations, norm=\"ortho\", axis=1)\n",
        "            # TODO: Remove the exact_covariance argument for real experiments.\n",
        "            estimated_covariance: Matrix = low_rank_multi_reference_factor_analysis(\n",
        "                observations_fourier, signal_length, approximation_rank, noise_power, data_type, exact_covariance)\n",
        "            mean_error += calc_estimation_error(exact_covariance, estimated_covariance)\n",
        "\n",
        "        mean_error /= trials_num\n",
        "        print(f'Finished experiment of signal length L={signal_length}, n={observations_num}, '\n",
        "              f'r={approximation_rank}, noise={noise_power} with error {mean_error}')\n",
        "\n",
        "        # Appending all the experiment results to the log.\n",
        "        results_log.append(LogFields.DataSize, signal_length)\n",
        "        results_log.append(LogFields.DataType, data_type.__name__)\n",
        "        results_log.append(LogFields.ApproximationRank, approximation_rank)\n",
        "        results_log.append(LogFields.NoisePower, noise_power)\n",
        "        results_log.append(LogFields.ObservationsNumber, observations_num)\n",
        "        results_log.append(LogFields.TrialsNum, trials_num)\n",
        "        results_log.append(LogFields.ShiftsDistribution, shifts_distribution_type)\n",
        "        results_log.append(LogFields.MeanError, mean_error)\n",
        "\n",
        "    results_log.save_log(f'{experiment_name} results', results_folder_path=results_path)\n",
        "    return results_log\n",
        "\n",
        "pd.DataFrame(ex.run().result._data)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING - Initializing project - No observers have been added to this run\n",
            "INFO - Initializing project - Running command 'main'\n",
            "INFO - Initializing project - Started\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Covariance Fourier Diagonal: [0.44254662 0.02560909 0.09368245 0.01462619 0.06994176 0.16883959\n",
            " 0.0441985  0.09270842 0.01692912 0.03091827]\n",
            "Power spectrum: [0.44281827 0.02559436 0.093596   0.01463897 0.06988274 0.16880402\n",
            " 0.04415838 0.09264484 0.01692436 0.03089064]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO - Initializing project - Result: <__main__.DataLog object at 0x7f24bb40a7f0>\n",
            "INFO - Initializing project - Completed after 0:00:51\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Min score: 0.01011640166361909\n",
            "Are matrices None? [False, False, False, False, False, False, False, False, False]\n",
            "Are matrices Hermitian? [True, True, True, True, True, True, True, True, True]\n",
            "Are matrices PSD? [False, False, False, False, False, False, False, False, False]\n",
            "Finished experiment of signal length L=10, n=1000000, r=2, noise=0.0 with error 0.4439374177848892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r</th>\n",
              "      <th>Data size</th>\n",
              "      <th>Data type (complex/real)</th>\n",
              "      <th>Mean Error</th>\n",
              "      <th>Noise power</th>\n",
              "      <th>Observations Number</th>\n",
              "      <th>Shifts Distribution</th>\n",
              "      <th>Number of Trials</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>complex128</td>\n",
              "      <td>0.443937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000000</td>\n",
              "      <td>Uniform Distribution</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   r  Data size  ...   Shifts Distribution  Number of Trials\n",
              "0  2         10  ...  Uniform Distribution                 1\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54tlMRvbhZK7",
        "colab_type": "text"
      },
      "source": [
        "#Unit-Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLspq7ujhbuR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "885541b0-e75f-4f43-d33b-a7daa44f6735"
      },
      "source": [
        "#@title Test Diagonal Extraction and Construction\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "test_diagonal_extraction_and_construction.py - tests for data creation methods\n",
        "===============================================================================\n",
        "\n",
        "This module contains the tests for the diagonals' extraction method and the estimator construction method\n",
        "for the first part of the algorithm.\n",
        "\n",
        "\"\"\"\n",
        "import unittest\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TestDiagonalExtractionAndConstruction(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    A class which contains tests for the diagonals extraction method, and the method for constructing\n",
        "    a matrix, given these diagonals\n",
        "    \"\"\"\n",
        "    def test_diagonals_extraction(self):\n",
        "        \"\"\"\n",
        "        Test diagonals extraction\n",
        "\n",
        "        This test validates the extract_diagonals take the maximal eigenvector from each matrix in its first dimension\n",
        "        and scales it w.r.t square-root of the maximal eigenvalue.\n",
        "\n",
        "        \"\"\"\n",
        "        mat_num: int = 4\n",
        "        max_eigenvalue: float = 9.0\n",
        "        sqrt_max_eigenvalue: float = np.sqrt(max_eigenvalue)\n",
        "        mat: Matrix = np.asfortranarray(np.tile(np.diag([3.0, max_eigenvalue, -4.0, -2.0]), (mat_num - 1, 1, 1)))\n",
        "        diagonals: Matrix = extract_diagonals(mat, mat_num)\n",
        "        expected_output: Matrix = np.tile(np.array([0, sqrt_max_eigenvalue, 0, 0]), (3, 1))\n",
        "        self.assertTrue(np.allclose(diagonals, expected_output))\n",
        "\n",
        "    def test_estimator_construction(self):\n",
        "        \"\"\"\n",
        "        Test methods equivalence.\n",
        "\n",
        "        This test validates that both the naive method and the improved method return identical\n",
        "        output (up to numerical inaccuracies) for some random signal.\n",
        "\n",
        "        \"\"\"\n",
        "        mat_num: int = 4\n",
        "        max_eigenvalue: float = 9.0\n",
        "        sqrt_max_eigenvalue: float = np.sqrt(max_eigenvalue)\n",
        "        mat: Matrix = np.asfortranarray(np.tile(np.diag([3.0, max_eigenvalue, -4.0, -2.0]), (mat_num - 1, 1, 1)))\n",
        "        diagonals: Matrix = extract_diagonals(mat, mat_num)\n",
        "        power_spectrum: Vector = np.array(4 * [1.0])\n",
        "        estimator: Matrix = construct_estimator(diagonals, power_spectrum, 4, 0)\n",
        "        expected_output: Matrix = np.eye(4)\n",
        "        expected_output[1] = np.array([sqrt_max_eigenvalue, 1, sqrt_max_eigenvalue, sqrt_max_eigenvalue])\n",
        "        self.assertTrue(np.allclose(estimator, expected_output))\n",
        "\n",
        "print(\"Loaded Unit-Tests for diagonal extraction and construction successfully!\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Unit-Tests for diagonal extraction and construction successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-_k6PFzlhin",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5674a534-fb29-46a1-ab9d-54de7b4a1d75"
      },
      "source": [
        "#@title Test Phase-Retrieval Actions\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "test_phase_retrieval_actions.py - tests for the stages in the phase retrieval algorithm\n",
        "=======================================================================================\n",
        "\n",
        "This module contains the tests for the different stages of the phase-retrieval algorithm:\n",
        "constructing the coefficients matrix and the Fourier basis transition of the fixed covariance estimator.\n",
        "\n",
        "\"\"\"\n",
        "import unittest\n",
        "import numpy as np\n",
        "from numpy.random import Generator, PCG64\n",
        "from numpy.fft import ifft, fft\n",
        "from scipy.linalg import dft, eigh, block_diag, circulant\n",
        "\n",
        "\n",
        "class TestPhaseRetrievalActions(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    A class which tests components of the phase-retrieval algorithm\n",
        "    \"\"\"\n",
        "    def test_fourier_matrices_product(self):\n",
        "        \"\"\"\n",
        "        Test Fourier basis transition\n",
        "\n",
        "        This test validates that the transition of a matrix from Fourier basis to the standard basis is equivalent to\n",
        "        multiplying my the DFT matrix from right and its inverse from the left.\n",
        "\n",
        "        \"\"\"\n",
        "        rng = Generator(PCG64(1995))\n",
        "        n: int = rng.integers(low=2, high=100)\n",
        "        mat: Matrix = rng.standard_normal((n, n))\n",
        "        tested_output = np.conj(ifft(mat, axis=0, norm=\"ortho\").T)\n",
        "        tested_output = np.conj(ifft(tested_output, axis=0, norm=\"ortho\").T)\n",
        "        dft_mat: Matrix = dft(n, scale=\"sqrtn\")\n",
        "        expected_output: Matrix = np.conj(dft_mat.T).dot(mat).dot(dft_mat)\n",
        "        self.assertTrue(np.allclose(tested_output, expected_output))\n",
        "\n",
        "        mat: Matrix = rng.standard_normal((n, n))\n",
        "        mat_fourier: Matrix = np.conj(fft(mat, axis=0, norm=\"ortho\").T)\n",
        "        mat_fourier: Matrix = np.conj(fft(mat_fourier, axis=0, norm=\"ortho\").T)\n",
        "        expected_output: Matrix = dft_mat.dot(mat).dot(np.conj(dft_mat.T))\n",
        "        self.assertTrue(np.allclose(mat_fourier, expected_output))\n",
        "\n",
        "    def test_coefficient_matrix_construction(self):\n",
        "        \"\"\"\n",
        "        Test coefficient matrix properties\n",
        "\n",
        "        This test validates that the coefficients matrix in the phase retrieval algorithm follows the\n",
        "        theoretical properties.\n",
        "\n",
        "        \"\"\"\n",
        "        rng = Generator(PCG64(1995))\n",
        "        n: int = rng.integers(low=9, high=20)\n",
        "        r: int = rng.integers(low=2, high=np.floor(np.sqrt(n)))\n",
        "        mat: Matrix = rng.standard_normal((n, n))\n",
        "        mat = np.dot(mat, mat.T)\n",
        "        coeff_mat: Matrix = coefficient_matrix_construction(mat, signal_length=n, approximation_rank=r)\n",
        "        self.assertEqual(coeff_mat.shape[0], n ** 3)\n",
        "        self.assertEqual(coeff_mat.shape[1], (1 + r ** 4) * n)\n",
        "\n",
        "        other_mat: Matrix = matrix_construction_alternative(mat, signal_length=n, approximation_rank=r)\n",
        "        self.assertTrue(np.allclose(coeff_mat, other_mat), msg=f'{np.max(np.abs(other_mat - coeff_mat))}')\n",
        "\n",
        "\n",
        "def matrix_construction_alternative(covariance_estimator: Matrix, signal_length: int,\n",
        "                                    approximation_rank: Union[int, None]) -> Matrix:\n",
        "    hi_i: Matrix = np.power(np.abs(covariance_estimator), 2)\n",
        "    rotated_mat: Matrix = covariance_estimator.copy()\n",
        "    rank_sqr: int = approximation_rank ** 2 if approximation_rank is not None else signal_length - 1\n",
        "    least_eigenvalue_index: int = signal_length - rank_sqr\n",
        "    last_index: int = signal_length ** 2\n",
        "    all_eigenvectors: Matrix = np.empty((signal_length, signal_length, rank_sqr), order=\"F\",\n",
        "                                        dtype=covariance_estimator.dtype)\n",
        "    all_m_mats: Matrix = np.zeros((signal_length ** 3, signal_length), dtype=covariance_estimator.dtype)\n",
        "\n",
        "    for i in range(signal_length):\n",
        "        all_eigenvectors[i] = eigh(hi_i, overwrite_b=False, check_finite=False,\n",
        "                                   eigvals=(least_eigenvalue_index, signal_length - 1))[1]\n",
        "        rotated_mat = np.roll(rotated_mat, shift=1, axis=1)\n",
        "        hi_i = np.multiply(covariance_estimator, np.conj(rotated_mat))\n",
        "        hi_i_plus_one_flat = hi_i.flatten('F')\n",
        "\n",
        "        for m in range(signal_length):\n",
        "            em = np.zeros(signal_length)\n",
        "            em[m] = 1\n",
        "            circ = circulant(em).flatten('F')\n",
        "            all_m_mats[i * last_index : (i + 1) * last_index, m] = np.multiply(hi_i_plus_one_flat, circ)\n",
        "        rotated_mat = np.roll(rotated_mat, shift=1, axis=0)\n",
        "        hi_i = np.multiply(covariance_estimator, np.conj(rotated_mat))\n",
        "\n",
        "    matrix_a = np.hstack((all_m_mats, -block_diag(*vectorized_kron(all_eigenvectors))))\n",
        "    return matrix_a\n",
        "\n",
        "\n",
        "print(\"Loaded Unit-Tests for Phase-Retrieval actions successfully!\")\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Unit-Tests for Phase-Retrieval actions successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXYvCiGl2sa",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b2d882a2-b1b8-4b82-c40d-71a25307220a"
      },
      "source": [
        "#@title Test Power-Spectrum and Tri-Spectrum Estimation Methods \n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "test_tri_spectrum_estimation.py - tests for spectra estimation methods\n",
        "======================================================================\n",
        "\n",
        "This module contains the tests for the power-spectrum and tri-spectrum estimation methods.\n",
        "\"\"\"\n",
        "import unittest\n",
        "import numpy as np\n",
        "from numpy.random import Generator, PCG64\n",
        "\n",
        "def calc_exact_tri_spectrum(exact_covariance: Matrix, data_type) -> ThreeDMatrix:\n",
        "    signal_length: int = exact_covariance.shape[0]\n",
        "    tri_spectrum = np.empty((signal_length, signal_length, signal_length), dtype=exact_covariance.dtype)\n",
        "\n",
        "    for i, j, k in product(range(signal_length), range(signal_length), range(signal_length)):\n",
        "        fourth_index = (k - j + i) % signal_length\n",
        "        tri_spectrum[i, j, k] = exact_covariance[i, j] * np.conj(exact_covariance[fourth_index, k])\n",
        "        tri_spectrum[i, j, k] += exact_covariance[i, fourth_index] * np.conj(exact_covariance[j, k])\n",
        "\n",
        "        if data_type in [np.float32, np.float64]:\n",
        "            tri_spectrum[i, j, k] += exact_covariance[i, (-k % signal_length)] * np.conj(\n",
        "                exact_covariance[j, (-fourth_index % signal_length)])\n",
        "\n",
        "    return tri_spectrum\n",
        "\n",
        "\n",
        "class TestTriSpectrumAlgorithms(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    A class which contains tests for the tri-spectrum estimation algorithms.\n",
        "    \"\"\"\n",
        "    def test_equivalence_to_naive_method(self):\n",
        "        \"\"\"\n",
        "        Test methods equivalence.\n",
        "\n",
        "        This test validates that both the naive method and the improved method return identical\n",
        "        output (up to numerical inaccuracies) for some random signal.\n",
        "\n",
        "        \"\"\"\n",
        "        rng = Generator(PCG64(596))\n",
        "        signal_length: int = rng.integers(low=10, high=40)\n",
        "        observations_num: int = rng.integers(low=5, high=20)\n",
        "        approximation_rank: int = rng.integers(low=5, high=20)\n",
        "        data_type = np.complex128\n",
        "        covariance, eigenvectors, eigenvalues = generate_covariance(signal_length, approximation_rank, data_type, rng)\n",
        "        observations = generate_observations(eigenvectors, eigenvalues, approximation_rank, observations_num,\n",
        "                                             data_type, rng)\n",
        "        observations_fourier: Matrix = np.fft.fft(observations, axis=1, norm=\"ortho\")\n",
        "        tri_spectrum_naive: ThreeDMatrix = estimate_tri_spectrum_naive(observations_fourier)\n",
        "        tri_spectrum_improved: ThreeDMatrix = estimate_tri_spectrum_v2(observations_fourier)\n",
        "        # Validate both tri-spectra are equal\n",
        "        self.assertTrue(np.allclose(np.abs(tri_spectrum_naive), np.abs(tri_spectrum_improved)),\n",
        "                        msg=f'{np.max(np.abs(tri_spectrum_improved - tri_spectrum_naive))}')\n",
        "        self.assertTrue(np.allclose(np.angle(tri_spectrum_naive), np.angle(tri_spectrum_improved)),\n",
        "                        msg=f'{np.max(np.angle(tri_spectrum_improved) - np.angle(tri_spectrum_naive))}')\n",
        "\n",
        "    def test_power_spectrum_and_tri_spectrum_consistency(self):\n",
        "        \"\"\"\n",
        "        Test the consistency of the power-spectrum estimation.\n",
        "\n",
        "        This test validates that the estimation over a large number of observations (without noise)\n",
        "        is \"very close\" to the exact power-spectrum\n",
        "\n",
        "        \"\"\"\n",
        "        rng = Generator(PCG64(596))\n",
        "        signal_length: int = rng.integers(low=10, high=40)\n",
        "        observations_num: int = rng.integers(low=10000, high=50000)\n",
        "        approximation_rank: int = rng.integers(low=2, high=signal_length)\n",
        "        data_type = np.complex128\n",
        "        tol = 1e-3\n",
        "        exact_covariance, eigenvectors, eigenvalues = generate_covariance(signal_length, approximation_rank, data_type,\n",
        "                                                                          rng)\n",
        "        observations = generate_observations(eigenvectors, eigenvalues, approximation_rank, observations_num,\n",
        "                                             data_type, rng)\n",
        "        observations_fourier: Matrix = np.fft.fft(observations, norm=\"ortho\")\n",
        "        exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_covariance, axis=0, norm=\"ortho\").T)\n",
        "        exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_cov_fourier_basis, axis=0, norm=\"ortho\").T)\n",
        "        exact_diagonal: Vector = np.real(np.diag(exact_cov_fourier_basis))\n",
        "        power_spectrum_estimation: Vector = estimate_power_spectrum(observations_fourier)\n",
        "        exact_tri_spectrum: ThreeDMatrix = calc_exact_tri_spectrum(exact_cov_fourier_basis, data_type)\n",
        "        estimate_tri_spectrum: ThreeDMatrix = estimate_tri_spectrum_v2(observations_fourier)\n",
        "\n",
        "        # Validate both tri-spectrum and power-spectrum estimations are consistent.\n",
        "        self.assertTrue(np.allclose(exact_diagonal, power_spectrum_estimation, atol=tol, rtol=0),\n",
        "                        msg=f'Power-spectrum estimation is inconsistent!')\n",
        "        self.assertTrue(np.allclose(estimate_tri_spectrum, exact_tri_spectrum, atol=tol, rtol=0),\n",
        "                        msg=f'Tri-spectrum estimation is inconsistent!, error=' +\n",
        "                            f'{np.max(np.abs(estimate_tri_spectrum - exact_tri_spectrum))}')\n",
        "\n",
        "    def test_real_data_tri_spectrum_consistency(self):\n",
        "        \"\"\"\n",
        "        Test the consistency of the tri-spectrum estimation in the case of REAL data (since the exact\n",
        "        tri-spectrum becomes more complicated in this case).\n",
        "\n",
        "        This test validates that the estimation over a large number of observations (without noise)\n",
        "        is \"very close\" to the exact tri-spectrum\n",
        "\n",
        "        \"\"\"\n",
        "        rng = Generator(PCG64(596))\n",
        "        signal_length: int = rng.integers(low=10, high=40)\n",
        "        observations_num: int = rng.integers(low=10000, high=50000)\n",
        "        approximation_rank: int = rng.integers(low=2, high=signal_length)\n",
        "        data_type = np.float64\n",
        "        tol = 1e-3\n",
        "        exact_covariance, eigenvectors, eigenvalues = generate_covariance(signal_length, approximation_rank, data_type,\n",
        "                                                                          rng)\n",
        "        observations = generate_observations(eigenvectors, eigenvalues, approximation_rank, observations_num,\n",
        "                                             data_type, rng)\n",
        "        observations_fourier: Matrix = np.fft.fft(observations, norm=\"ortho\")\n",
        "        exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_covariance, axis=0, norm=\"ortho\").T)\n",
        "        exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_cov_fourier_basis, axis=0, norm=\"ortho\").T)\n",
        "        exact_tri_spectrum: ThreeDMatrix = calc_exact_tri_spectrum(exact_cov_fourier_basis, data_type)\n",
        "        estimate_tri_spectrum: ThreeDMatrix = estimate_tri_spectrum_v2(observations_fourier)\n",
        "\n",
        "        # Validate the tri-spectrum estimation in the real case is consistent.\n",
        "        self.assertTrue(np.allclose(estimate_tri_spectrum, exact_tri_spectrum, atol=tol, rtol=0),\n",
        "                        msg=f'Tri-spectrum estimation is inconsistent!, error=' +\n",
        "                            f'{np.max(np.abs(estimate_tri_spectrum - exact_tri_spectrum))}')\n",
        "\n",
        "print(\"Loaded Unit-Tests for Power-Spectrum and Tri-Spectrum Estimation successfully!\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Unit-Tests for Power-Spectrum and Tri-Spectrum Estimation successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2a0ZzcICcmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "outputId": "c6fc5fd1-8d8a-4553-afe9-add7e86661a2"
      },
      "source": [
        "#@title Test Optimization Step Components \n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "test_optimization_step.py - tests for the optimization step components\n",
        "======================================================================\n",
        "\n",
        "This module contains the tests for the optimization step in Algorithm 1\n",
        "in the paper.\n",
        "\"\"\"\n",
        "import unittest\n",
        "import numpy as np\n",
        "from numpy.random import Generator, PCG64\n",
        "\n",
        "\n",
        "def _create_optimization_objective(tri_spectrum, power_spectrum, data_type) -> Callable:\n",
        "    g_zero = np.outer(power_spectrum, power_spectrum)\n",
        "    signal_length = len(power_spectrum)\n",
        "\n",
        "    def objective(matrices_list):\n",
        "        fit_score = 0.0\n",
        "        current_matrices_list = np.concatenate(([g_zero], matrices_list), axis=0)\n",
        "        for k1 in range(signal_length):\n",
        "            for k2 in range(signal_length):\n",
        "                other_index = (k2 - k1) % signal_length\n",
        "                k1_plus_m = k1\n",
        "                k2_plus_m = k2\n",
        "                for m in range(signal_length):\n",
        "                    current_term = tri_spectrum[k1, k1_plus_m, k2_plus_m]\n",
        "                    current_term -= current_matrices_list[other_index][k1, k1_plus_m]\n",
        "                    current_term -= current_matrices_list[m][k1, k2]\n",
        "\n",
        "                    if data_type in [np.float32, np.float64]:\n",
        "                        next_index: int = (k1 + k2 + m) % signal_length\n",
        "                        current_term -= current_matrices_list[next_index][(-k2) % signal_length,\n",
        "                                                                          (-k2 - m) % signal_length]\n",
        "\n",
        "                    k1_plus_m = (k1_plus_m + 1) % signal_length\n",
        "                    k2_plus_m = (k2_plus_m + 1) % signal_length\n",
        "                    fit_score += abs(current_term) ** 2\n",
        "        return fit_score\n",
        "    return objective\n",
        "\n",
        "\n",
        "def _find_diagonals(exact_covariance: Matrix) -> Matrix:\n",
        "    \"\"\"\n",
        "    The function extracts the diagonals of the exact covariance matrix (in Fourier basis).\n",
        "    Args:\n",
        "        exact_covariance(Matrix): The exact covariance (square) matrix in Fourier basis.\n",
        "\n",
        "    Returns:\n",
        "        A square matrix such that its i-th row is the i-th diagonal of the input matrix.\n",
        "    \"\"\"\n",
        "    signal_length: int = exact_covariance.shape[0]\n",
        "    diags: Matrix = np.empty((signal_length - 1, signal_length), dtype=exact_covariance.dtype)\n",
        "\n",
        "    for i in range(1, signal_length):\n",
        "        diags[i - 1] = np.hstack((np.diagonal(exact_covariance, offset=i),\n",
        "                                  np.diagonal(exact_covariance, offset=-signal_length + i)))\n",
        "    return diags\n",
        "\n",
        "\n",
        "def _test_optimization_template(data_type, signal_length, approximation_rank, seed):\n",
        "    rng = Generator(PCG64(seed))\n",
        "    exact_covariance, eigenvectors, eigenvalues = generate_covariance(signal_length, approximation_rank, data_type, rng)\n",
        "    exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_covariance, axis=0, norm=\"ortho\").T)\n",
        "    exact_cov_fourier_basis: Matrix = np.conj(np.fft.fft(exact_cov_fourier_basis, axis=0, norm=\"ortho\").T)\n",
        "    exact_power_spectrum: Vector = np.real(np.diag(exact_cov_fourier_basis))\n",
        "    exact_tri_spectrum: ThreeDMatrix = calc_exact_tri_spectrum(exact_cov_fourier_basis, data_type)\n",
        "    diagonals = _find_diagonals(exact_cov_fourier_basis)\n",
        "    g_mats = np.array([diagonal.reshape(-1, 1).dot(np.conj(diagonal.reshape(-1, 1).T)) for diagonal in diagonals])\n",
        "    optimization_object: Callable = _create_optimization_objective(exact_tri_spectrum, exact_power_spectrum, data_type)\n",
        "    return optimization_object(g_mats), exact_tri_spectrum, exact_power_spectrum\n",
        "\n",
        "\n",
        "class TestOptimization(unittest.TestCase):\n",
        "    \"\"\"\n",
        "    A class which contains tests for the optimization step of Algorithm 1.\n",
        "    \"\"\"\n",
        "    def test_optimization_complex_case(self):\n",
        "        \"\"\"\n",
        "        Test the optimization objective function for the complex case.\n",
        "\n",
        "        This test creates the optimal input matrices for the objective function\n",
        "        and then verifies the value of the objective function, given these matrices as input,\n",
        "        is very close to zero. In addition, this function verifies the theoretical equation between\n",
        "        the main \"diagonal\" of the tri-spectrum and two times the square of the power-spectrum squared.\n",
        "        \"\"\"\n",
        "        seed: int = 1995\n",
        "        data_type = np.complex128\n",
        "        signal_length: int = 3\n",
        "        approximation_rank: int = signal_length\n",
        "        min_value, exact_tri_spectrum, exact_power_spectrum = _test_optimization_template(\n",
        "            data_type, signal_length, approximation_rank, seed)\n",
        "        tri_diagonal: Vector = np.array([np.real(exact_tri_spectrum[i, i, i]) for i in range(signal_length)],\n",
        "                                        dtype=np.float64)\n",
        "        min_expected_value = np.abs(tri_diagonal - 2 * np.power(exact_power_spectrum, 2))\n",
        "        min_expected_value = np.sum(min_expected_value)\n",
        "        print(f'Minimal objective function value in the COMPLEX case: {min_value}')\n",
        "        self.assertTrue(np.allclose(min_value, 0, atol=1e-20, rtol=0), msg=f'Minimal value is NOT optimal={min_value}')\n",
        "        self.assertEqual(min_expected_value, 0,\n",
        "                         msg=f'Tri-spectrum and power-spectrum estimation error={min_expected_value}')\n",
        "\n",
        "    def test_optimization_real_case(self):\n",
        "        \"\"\"\n",
        "        Test the optimization objective function for the real case.\n",
        "\n",
        "        This test creates the optimal input matrices for the objective function\n",
        "        and then verifies the value of the objective function, given these matrices as input,\n",
        "        is very close to zero. In addition, this function verifies the theoretical equation between\n",
        "        the first term of the tri-spectrum and three times the square of the first entry of the power-spectrum squared.\n",
        "        \"\"\"\n",
        "        seed: int = 1995\n",
        "        data_type = np.float64\n",
        "        signal_length: int = 3\n",
        "        approximation_rank: int = signal_length\n",
        "        min_value, exact_tri_spectrum, exact_power_spectrum = _test_optimization_template(data_type, signal_length,\n",
        "                                                                                          approximation_rank, seed)\n",
        "        tri_diagonal: Vector = np.array([np.real(exact_tri_spectrum[i, i, i]) for i in range(signal_length)],\n",
        "                                        dtype=np.float64)\n",
        "        min_expected_value = np.abs(tri_diagonal[0] - 3 * np.power(exact_power_spectrum[0], 2))\n",
        "        print(f'Minimal objective function value in the REAL case: {min_value}')\n",
        "        self.assertTrue(np.allclose(min_value, 0, atol=1e-20, rtol=0), msg=f'Minimal value is NOT optimal={min_value}')\n",
        "        self.assertEqual(min_expected_value, 0, msg=f'Tri-spectrum and power-spectrum estimation error={min_value}')\n",
        "\n",
        "print(\"Loaded Unit-Tests for Optimization step successfully!\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Unit-Tests for Optimization step successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqYX5WSIlfOQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b1990214-0e2e-4b57-9354-9ac6792132d8"
      },
      "source": [
        "#@title Running all these Unit-Tests\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_diagonals_extraction (__main__.TestDiagonalExtractionAndConstruction) ... ok\n",
            "test_estimator_construction (__main__.TestDiagonalExtractionAndConstruction) ... ok\n",
            "test_optimization_complex_case (__main__.TestOptimization) ... ok\n",
            "test_optimization_real_case (__main__.TestOptimization) ... ok\n",
            "test_coefficient_matrix_construction (__main__.TestPhaseRetrievalActions) ... "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Minimal objective function value in the COMPLEX case: 3.746239375889483e-34\n",
            "Minimal objective function value in the REAL case: 5.900805778551215e-33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "test_fourier_matrices_product (__main__.TestPhaseRetrievalActions) ... ok\n",
            "test_equivalence_to_naive_method (__main__.TestTriSpectrumAlgorithms) ... ok\n",
            "test_power_spectrum_and_tri_spectrum_consistency (__main__.TestTriSpectrumAlgorithms) ... ok\n",
            "test_real_data_tri_spectrum_consistency (__main__.TestTriSpectrumAlgorithms) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 9 tests in 78.788s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f24bba0fdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}